<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Jose Velasquez Sosa</title>
    <link rel="stylesheet" href="https://unpkg.com/purecss@1.0.0/build/pure-min.css"
          integrity="sha384-nn4HPE8lTHyVtfCBi5yW9d20FjT8BJwUXyWZT9InLYax14RDjBj46LmSztkmNP9w" crossorigin="anonymous">
    <link rel="stylesheet" href="css/layouts/blog.css">
    <link rel="stylesheet" href="https://unpkg.com/purecss@1.0.0/build/grids-responsive-min.css">
</head>


<body>

<div id="layout" class="pure-g">
    <div class="sidebar pure-u-1 pure-u-md-1-4">
        <div class="header">
            <h1 class="brand-title">Data Science and Machine Learning Portfolio</h1>
            <h2 class="brand-tagline">Author: Jose Luis Velasquez Sosa</h2>

            <nav class="nav">
                <ul class="nav-list">
                    <li class="nav-item">
                        <a class="pure-button" href="index.html">Home</a>
                    </li>
                    <li class="nav-item">
                        <a href="https://www.linkedin.com/in/jlveso/" target = "_blank" class="pure-button">LinkedIn</a>
                    </li>
                    <li class="nav-item">
                        <a href="https://twitter.com/jlveso" target = "_blank" class="pure-button">Twitter</a>
                    </li>
                    <li class="nav-item">
                        <a class="pure-button" href="mailto:jvelasquezsosa96@gmail.com">Email</a>
                    </li>
                    <li class="nav-item">
                        <a class="pure-button" target="_blank "href="resources/Resume.pdf">Resume</a>
                    </li>
                </ul>
            </nav>
        </div>
    </div>

    <div class="content pure-u-1 pure-u-md-3-4">
        <div class="posts">
            
            <div class="post-description">
                <header class="post-header">
                    <h3 class="post-title">Introduction</h3>
                </header>
                <img class="pure-img center" src="https://drive.google.com/uc?id=121oxF1m67HBhqjtmguvAgDld9_2Yh4Ks" 
                alt="My Picture" width="100" height="120"/>
                <br/>
                <p>
                This page is meant to show some of my work and applications of Data Analysis and Data Science. The 
                first two posts are sceintific articles written during my Bachelor in Data Science and Knowledge Engineering.
                The posts follow these first two are notebooks and blogs showing Data Analysis and Machine Learning applications.
                </p>
                <br/>
            </div>
            <h1 class="content-subhead">Thesis and Research Projects</h1>
            <section class="post">
                <header class="post-header">
                    <h3 class="post-title">Neural Attention and Morphological Word Embedding</h3>
                    <p class="post-meta"><a target="_blank" href="resources/Thesis.pdf">Paper</a></p>
                </header>
                <div class="post-description">
                    <p>
                        Contract element extraction tries to identify the most important facts and entities of a contract
                        in order to keep an accurate track of a legal corpus. The introduction of neural attention
                        mechanism and morphological word embedding are added to the previously proposed element extractors,
                        the Bidirectional Long-Short Term Memory network with a Conditional Random Field (BiLSTM-CRF)
                        and the stacked BiLSTM-LSTM with a logistic regression as a output(BiLSTM-LSTM-LR),
                        to explore their effect on the extracting task. No significant effect was found, on the introduction
                        of attention mechanism. However, statistically significant results with a p-value of 0.006 suggests
                        that the introduction of morphological embedding helps the BiLSTM-CRF and BiLSTM-LSTM-LR architectures perform better.
                    </p>
                </div>
            </section>
            <section class="post">
                <header class="post-header">
                    <h3 class="post-title">AI for Hex</h3>
                    <p class="post-meta"><a target="_blank" href="resources/Hex.pdf">Paper</a></p>
                </header>
                <div class="post-description">
                    <p>
                        Hex is a classic board game invented in 1942 by Piet Hein and independently by John Nash in 1948.
                        In this paper there is research into Alpha- Beta and Monte-Carlo Tree Search (MCTS) Hex players,
                        as well as comparisons of different evaluation functions which includes Dijkstra and Electric Circuit.
                        In addition to this Monte-Carlo Tree Search specific heuristics, Upper Confidence Threshold (UCT)
                        and All Moves As First (AMAF), are compared. The most optimal versions of every implementations were found,
                        showing that the UCT policy in the MCTS algorithm has a better performance over all the other techniques tested.
                    </p>
                </div>
            </section>
        </div>
        <div class="posts">
            <h1 class="content-subhead">Data Analysis</h1>
            <!--
            <section class="post">
                <header class="post-header">
                    <h3 class="post-title">Exploratory Data Analysis</h3>
                    <p class="post-meta"><a href="pages/data_analysis/eda.html">Notebook</a></p>
                </header>
                <div class="post-description">
                    <p>
                        Jerry is thinking of going viral on YouTube with inspirational videos about what you should do to be the coolest
                        person in the world. For this reason, he thought of checking what drives the views of TED talks up and collected
                        the information about different TED talks via a scrapping tool.
                    </p>
                </div>
            </section> 
            -->
            <section class="post">
                <header class="post-header">
                    <h3 class="post-title">Statistical Learning</h3>
                    <p class="post-meta"><a href="pages/data_analysis/statistical_learning.html">Notebook</a></p>
                </header>
                <div class="post-description">
                    <p>
                        We will inspect the dataset “uni.csv” which contains data for different US universities.
                        We will perform the necessary data exploration in order to try investigate
                        which linear model better predicts the number of applicants for each university.
                    </p>
                </div>
            </section>
            <!--
            <section class="post">
                <header class="post-header">
                    <h3 class="post-title">Text Analysis</h3>
                    <p class="post-meta"><a href="pages/data_analysis/text_analysis.html">Notebook</a></p>
                </header>
                <div class="post-description">
                    <p>
                        We will be exploring the basics of text analysis. For this purpose we will use an e-mail dataset (Hillary Clinton’s).
                    </p>
                </div>
            </section>

            <section class="post">
                <header class="post-header">
                    <h3 class="post-title">Image Processing</h3>
                    <p class="post-meta"><a href="pages/data_analysis/image_processing.html">Notebook</a></p>
                </header>
                <div class="post-description">
                    <p>
                        In this notebook we will explore different image processing techniques.
                    </p>
                </div>
            </section>

            <section class="post">
                <header class="post-header">
                    <h3 class="post-title">Time and Frequency Domain Analysis</h3>
                    <p class="post-meta"><a href="pages/data_analysis/time_frequency.html">Notebook</a></p>
                </header>
                <div class="post-description">
                    <p>
                        In this notebook we will explore different techniques for timeseries analysis.
                        In addition, we also explore the frequency domain for image processing.
                    </p>
                </div>
            </section>

            <section class="post">
                <header class="post-header">
                    <h3 class="post-title">Dimensionality Reduction</h3>
                    <p class="post-meta"><a href="pages/data_analysis/dim_reduction.html">Notebook</a></p>
                </header>
                <div class="post-description">
                    <p>
                        In this notebook we review different dimensionality reduction algorithms.
                    </p>
                </div>
            </section>
        </div>
    -->
        <div class="posts">
            <h1 class="content-subhead">Machine Learning and Deep Learning</h1>
            <section class="post">
                <header class="post-header">
                    <h3 class="post-title">Time Series Prediction with Deep Learning</h3>
                    <p class="post-meta"><a href="pages/deep_learning/forecating_dl.html">Notebook</a></p>
                </header>
                <div class="post-description">
                    <p>
                        Exploration of different deep learning forecasting models for time series. Using birth data to compare their performance.
                    </p>
                </div>
            </section>
            <section class="post">
                <header class="post-header">
                    <h3 class="post-title">Lantent Space Interpolation with Autoencoders</h3>
                    <p class="post-meta"><a href="pages/deep_learning/latent_space_dl.html">Notebook</a></p>
                </header>
                <div class="post-description">
                    <p>
                        In this notebook we take the MNIST dataset and use different deep learning techniques to learn meaningful
                        representation in a lower dimensional space. We see how different techniques build different latent spaces.
                    </p>
                </div>
            </section>
        </div>
    </div>

</div>
</body>



</html>